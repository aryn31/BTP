{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d88b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. XGBoost and DB connection ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import random\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# --- ML Libraries ---\n",
    "# Using XGBoost for its robustness with tabular data\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "import joblib # For saving the model\n",
    "\n",
    "# --- Configuration (Must match your agent's configuration) ---\n",
    "DB_URI = \"mysql+pymysql://root:sql_my1country@localhost:3306/BTP\" # REPLACE with your actual URI\n",
    "engine = create_engine(DB_URI)\n",
    "\n",
    "# --- Global Settings ---\n",
    "# Time window for generating features\n",
    "LOOKBACK_DAYS = 30 \n",
    "# Total number of historical records to generate per patient (for training data)\n",
    "MAX_HISTORY_POINTS = 10 \n",
    "\n",
    "print(\"Setup complete. XGBoost and DB connection ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadd12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utility Functions (Copied from agent3.py) ===\n",
    "\n",
    "def _normalize_wearable_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Map various schema names to a consistent internal schema.\"\"\"\n",
    "    df = df.copy()\n",
    "    aliases = {\n",
    "        \"Steps\": [\"Steps\", \"steps\"],\n",
    "        \"HeartRate\": [\"HeartRate\", \"HeartRate_bpm\", \"heart_rate\"],\n",
    "        \"OxygenLevel\": [\"OxygenLevel\", \"SpO2\", \"oxygen_level\"],\n",
    "        \"StressLevel\": [\"StressLevel\", \"stress_level\"],\n",
    "        \"SystolicBP\": [\"SystolicBP\", \"BP_Sys\", \"bp_sys\"],\n",
    "        \"DiastolicBP\": [\"DiastolicBP\", \"BP_Dia\", \"bp_dia\"],\n",
    "        \"SleepHours\": [\"SleepHours\", \"Sleep_hrs\", \"sleep_hours\", \"sleep_cycle\"],\n",
    "        \"Timestamp\": [\"Timestamp\", \"ts\", \"Date\", \"date\"]\n",
    "    }\n",
    "    for std, opts in aliases.items():\n",
    "        for o in opts:\n",
    "            if o in df.columns:\n",
    "                df.rename(columns={o: std}, inplace=True)\n",
    "                break\n",
    "    for col in [\"Steps\", \"HeartRate\", \"OxygenLevel\", \"StressLevel\", \"SystolicBP\", \"DiastolicBP\", \"SleepHours\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    if \"Timestamp\" in df.columns:\n",
    "        df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def generate_ml_features(pid: int, as_of_date: datetime, lookback_days: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generates a dictionary of ML features for a patient as of a specific date.\n",
    "    This is the core feature extraction logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Static Features\n",
    "    patient_data = pd.read_sql(text(\"SELECT PatientID, DOB, Gender, BMI FROM Patients WHERE PatientID = :pid\"),\n",
    "                               engine, params={\"pid\": pid})\n",
    "    if patient_data.empty: return None\n",
    "        \n",
    "    p_row = patient_data.iloc[0]\n",
    "    # Age as of the as_of_date\n",
    "    age = (as_of_date.date() - p_row['DOB'].date()).days / 365.25 if pd.notna(p_row['DOB']) else 0\n",
    "    \n",
    "    features = {\n",
    "        \"PatientID\": pid,\n",
    "        \"Age\": age,\n",
    "        \"Gender_Male\": 1 if p_row.get('Gender', '').lower() == 'male' else 0,\n",
    "        \"BMI\": p_row.get('BMI', 25.0),\n",
    "    }\n",
    "\n",
    "    # 2. Condition Features\n",
    "    conditions_q = text(\"SELECT `Condition` FROM Conditions WHERE PatientID = :pid\")\n",
    "    conditions_df = pd.read_sql(conditions_q, engine, params={\"pid\": pid})\n",
    "    conditions_str = \" \".join(conditions_df['Condition'].fillna('').str.lower().tolist())\n",
    "    \n",
    "    features['HasDiabetes'] = 1 if 'diabetes' in conditions_str else 0\n",
    "    features['HasHTN'] = 1 if 'hypertension' in conditions_str else 0\n",
    "    \n",
    "    # 3. Longitudinal Wearable Features (up to as_of_date)\n",
    "    start_date = as_of_date - timedelta(days=lookback_days)\n",
    "    wearable_q = text(\"\"\"\n",
    "        SELECT * FROM WearableData\n",
    "        WHERE PatientID = :pid \n",
    "          AND Timestamp >= :start_date \n",
    "          AND Timestamp <= :end_date\n",
    "    \"\"\")\n",
    "    wearable_df = pd.read_sql(wearable_q, engine, \n",
    "                              params={\"pid\": pid, \"start_date\": start_date, \"end_date\": as_of_date})\n",
    "    \n",
    "    wearable_df = _normalize_wearable_columns(wearable_df)\n",
    "\n",
    "    if not wearable_df.empty:\n",
    "        # Aggregations for the lookback window\n",
    "        features['7DayMeanHR'] = wearable_df['HeartRate'].tail(7 * 24).mean()\n",
    "        features['MinSpO2_24h'] = wearable_df['OxygenLevel'].tail(24).min()\n",
    "        features['MaxSysBP_7d'] = wearable_df['SystolicBP'].tail(7).max()\n",
    "        features['AvgSleepHours'] = wearable_df['SleepHours'].mean()\n",
    "        features['DaysSinceLastReading'] = (as_of_date - wearable_df['Timestamp'].max()).days\n",
    "    else:\n",
    "         features.update({'7DayMeanHR': 90, 'MinSpO2_24h': 98, 'MaxSysBP_7d': 120, \n",
    "                          'AvgSleepHours': 7, 'DaysSinceLastReading': 999})\n",
    "    \n",
    "    # Placeholder for Lab Features: In a real scenario, you'd fetch the latest HBA1C here.\n",
    "    features['LatestHBA1C'] = random.uniform(5.0, 7.0) # Mock value\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dab768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching patient IDs...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'datetime.date' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(all_features).drop_duplicates()\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Generate the data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m df_train = \u001b[43mgenerate_training_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAX_HISTORY_POINTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOOKBACK_DAYS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining dataset generated with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m df_train.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mgenerate_training_dataset\u001b[39m\u001b[34m(max_points_per_patient, lookback_days)\u001b[39m\n\u001b[32m     26\u001b[39m     sample_dates.extend(unique_dates[:max_points_per_patient - \u001b[32m1\u001b[39m])\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m as_of_date \u001b[38;5;129;01min\u001b[39;00m sample_dates:\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# 1. Generate Features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     features = \u001b[43mgenerate_ml_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_of_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookback_days\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m features: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# 2. Determine Target (Labeling the risk/event)\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Find if an adverse event occurred within 30 days *after* the as_of_date\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mgenerate_ml_features\u001b[39m\u001b[34m(pid, as_of_date, lookback_days)\u001b[39m\n\u001b[32m     39\u001b[39m p_row = patient_data.iloc[\u001b[32m0\u001b[39m]\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Age as of the as_of_date\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m age = (as_of_date.date() - \u001b[43mp_row\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDOB\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate\u001b[49m()).days / \u001b[32m365.25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pd.notna(p_row[\u001b[33m'\u001b[39m\u001b[33mDOB\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     43\u001b[39m features = {\n\u001b[32m     44\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPatientID\u001b[39m\u001b[33m\"\u001b[39m: pid,\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m\"\u001b[39m: age,\n\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGender_Male\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p_row.get(\u001b[33m'\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).lower() == \u001b[33m'\u001b[39m\u001b[33mmale\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m,\n\u001b[32m     47\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBMI\u001b[39m\u001b[33m\"\u001b[39m: p_row.get(\u001b[33m'\u001b[39m\u001b[33mBMI\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m25.0\u001b[39m),\n\u001b[32m     48\u001b[39m }\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# 2. Condition Features\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'datetime.date' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "def generate_training_dataset(max_points_per_patient: int = 10, lookback_days: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates the full training dataset by sampling historical time points.\n",
    "    \"\"\"\n",
    "    print(\"Fetching patient IDs...\")\n",
    "    patient_ids = pd.read_sql(\"SELECT PatientID FROM Patients\", engine)['PatientID'].tolist()\n",
    "    \n",
    "    all_features = []\n",
    "    \n",
    "    for pid in patient_ids:\n",
    "        # Find all encounter dates to use as potential historical \"as_of\" points\n",
    "        encounter_dates = pd.read_sql(text(\n",
    "            \"SELECT `Date` FROM Encounters WHERE PatientID = :pid ORDER BY `Date` DESC\"\n",
    "        ), engine, params={\"pid\": pid})\n",
    "        \n",
    "        # Add the current date as the most recent point\n",
    "        sample_dates = [datetime.now()]\n",
    "        \n",
    "        # Add random historical dates up to MAX_HISTORY_POINTS\n",
    "        if not encounter_dates.empty:\n",
    "            dates = pd.to_datetime(encounter_dates['Date']).tolist()\n",
    "            # Select unique dates for sampling\n",
    "            unique_dates = sorted(list(set(dates)), reverse=True)\n",
    "            \n",
    "            # Select up to max_points_per_patient dates\n",
    "            sample_dates.extend(unique_dates[:max_points_per_patient - 1])\n",
    "            \n",
    "        \n",
    "        for as_of_date in sample_dates:\n",
    "            # 1. Generate Features\n",
    "            features = generate_ml_features(pid, as_of_date, lookback_days)\n",
    "            if not features: continue\n",
    "\n",
    "            # 2. Determine Target (Labeling the risk/event)\n",
    "            # Find if an adverse event occurred within 30 days *after* the as_of_date\n",
    "            \n",
    "            future_date = as_of_date + timedelta(days=30)\n",
    "            \n",
    "            # MOCK TARGET LABELING: HIGHLY SIMPLIFIED\n",
    "            # A real model would query for future hospitalization/ED visits.\n",
    "            # We mock the target based on features present at the time.\n",
    "            \n",
    "            # Target is 1 if patient was old AND high HR OR low SpO2 at that time\n",
    "            is_high_risk_feature = (features.get('Age', 0) > 65 and features.get('7DayMeanHR', 0) > 105) or \\\n",
    "                                   (features.get('MinSpO2_24h', 100) < 92)\n",
    "            \n",
    "            # Add some random noise to simulate real-world events\n",
    "            features['TARGET'] = 1 if is_high_risk_feature and random.random() < 0.6 else 0\n",
    "            \n",
    "            all_features.append(features)\n",
    "            \n",
    "    return pd.DataFrame(all_features).drop_duplicates()\n",
    "\n",
    "# Generate the data\n",
    "df_train = generate_training_dataset(MAX_HISTORY_POINTS, LOOKBACK_DAYS)\n",
    "print(f\"\\nTraining dataset generated with {len(df_train)} rows.\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77404c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
